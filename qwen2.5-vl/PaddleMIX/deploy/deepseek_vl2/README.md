# DeepSeek-VL2

[DeepSeek-VL2](https://github.com/deepseek-ai/DeepSeek-VL2) 基于大型混合专家（Mixture-of-Experts，MoE）视觉语言模型，相较于其前身DeepSeek-VL有了显著提升。DeepSeek-VL2在各种任务中展现出了卓越的能力。本仓库提供了DeepSeek-VL2高性能推理。
支持的权重如下：

|             Model               |
|---------------------------------|
| deepseek-ai/deepseek-vl2-small  |

## 环境安装
1） [安装PaddlePaddle](https://github.com/PaddlePaddle/PaddleMIX?tab=readme-ov-file#3-%EF%B8%8F%E5%AE%89%E8%A3%85paddlepaddle)
- **python >= 3.10**
- **paddlepaddle-gpu 要求develop版本**
```bash
# Develop 版本安装示例
python -m pip install --pre paddlepaddle-gpu -i https://www.paddlepaddle.org.cn/packages/nightly/cu118/
```

2） [安装PaddleMIX环境依赖包](https://github.com/PaddlePaddle/PaddleMIX?tab=readme-ov-file#3-%EF%B8%8F%E5%AE%89%E8%A3%85paddlepaddle)
```bash
# 安装paddlemix、ppdiffusers、项目依赖、PaddleNLP
sh build_env.sh --nlp_dev

# 此处提供两种paddlenlp_ops安装方法，建议使用预编译的paddlenlp_ops进行安装
# 手动编译安装paddlenlp_ops
cd PaddleNLP/csrc
python setup_cuda.py install

# 安装pre-build paddlenlp_ops
wget https://paddlenlp.bj.bcebos.com/wheels/paddlenlp_ops-ci-py3-none-any.whl -O paddlenlp_ops-0.0.0-py3-none-any.whl
pip install paddlenlp_ops-0.0.0-py3-none-any.whl
```


3） paddlenlp_ops预编译包安装表格，根据paddlenlp、CUDA版本选择配套paddlenlp_ops

<table class="docutils">
    <thead>
        <tr>
            <th width="80">CUDA</th>
            <th width="200">paddlenlp_3.0.0b4</th>
            <th width="200">paddlenlp_develop</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td align="center">12.4</td>
            <td>
                <details>
                    <summary>Install</summary>
                    <pre><code>pip install https://paddlenlp.bj.bcebos.com/ops/cu124/paddlenlp_ops-3.0.0b4-py3-none-any.whl</code></pre>
                </details>
            </td>
            <td></td>
        </tr>
        <tr>
            <td align="center">11.8</td>
            <td>
                <details>
                    <summary>Install</summary>
                    <pre><code>pip install https://paddlenlp.bj.bcebos.com/ops/cu118/paddlenlp_ops-3.0.0b4-py3-none-any.whl</code></pre>
                </details>
            </td>
            <td>
                <details>
                    <summary>Install</summary>
                    <pre><code>wget https://paddlenlp.bj.bcebos.com/wheels/paddlenlp_ops-ci-py3-none-any.whl -O paddlenlp_ops-0.0.0-py3-none-any.whl && pip install paddlenlp_ops-0.0.0-py3-none-any.whl</code></pre>
                </details>
            </td>
        </tr>
    </tbody>
</table>

## 3 高性能推理

### a. fp16 高性能推理

cd PaddleMIX

```
export CUDA_VISIBLE_DEVICES=0
export FLAGS_mla_use_tensorcore=0
export FLAGS_cascade_attention_max_partition_size=128
export FLAGS_cascade_attention_deal_each_time=16
export USE_FASTER_TOP_P_SAMPLING=1
python deploy/deepseek_vl2/deepseek_vl2_infer.py \
    --model_name_or_path deepseek-ai/deepseek-vl2-small \
    --question "Describe this image." \
    --image_file paddlemix/demo_images/examples_image1.jpg \
    --min_length 128 \
    --max_length 128 \
    --top_k 1 \
    --top_p 0.001 \
    --temperature 0.1 \
    --repetition_penalty 1.05 \
    --block_attn True \
    --append_attn True \
    --inference_model True \
    --llm_mode static \
    --dtype bfloat16 \
    --output_via_mq False \
    --benchmark True

# 多图推理
export CUDA_VISIBLE_DEVICES=0
export FLAGS_mla_use_tensorcore=0
export FLAGS_cascade_attention_max_partition_size=128
export FLAGS_cascade_attention_deal_each_time=16
export USE_FASTER_TOP_P_SAMPLING=1
python deploy/deepseek_vl2/deepseek_vl2_infer_multi_image.py \
    --model_name_or_path deepseek-ai/deepseek-vl2-small \
    --question "Can you tell me what are in the images?" \
    --image_file_1 paddlemix/demo_images/examples_image1.jpg \
    --image_file_2 paddlemix/demo_images/examples_image2.jpg \
    --image_file_3 paddlemix/demo_images/examples_image1.jpg \
    --min_length 128 \
    --max_length 128 \
    --block_attn True \
    --append_attn True \
    --inference_model True \
    --llm_mode static \
    --dtype bfloat16 \
    --top_k 1 \
    --top_p 0.001 \
    --temperature 0.1 \
    --repetition_penalty 1.05 \
    --output_via_mq False \
    --benchmark
```

### b. wint8 高性能推理
```
export CUDA_VISIBLE_DEVICES=0
export FLAGS_mla_use_tensorcore=0
export FLAGS_cascade_attention_max_partition_size=128
export FLAGS_cascade_attention_deal_each_time=16
export USE_FASTER_TOP_P_SAMPLING=1
python deploy/deepseek_vl2/deepseek_vl2_infer.py \
    --model_name_or_path deepseek-ai/deepseek-vl2-small \
    --question "Describe this image." \
    --image_file paddlemix/demo_images/examples_image1.jpg \
    --min_length 128 \
    --max_length 128 \
    --block_attn True \
    --append_attn True \
    --inference_model True \
    --llm_mode static \
    --dtype bfloat16 \
    --top_k 1 \
    --top_p 0.001 \
    --temperature 0.1 \
    --repetition_penalty 1.05 \
    --quant_type "weight_only_int8" \
    --output_via_mq False \
    --benchmark True
```

## 4 一键推理 & 推理说明
cd PaddleMIX
sh deploy/deepseek_vl2/scripts/deepseek_vl2.sh
#### 参数设定
|     parameter      |      Value     |
| ------------------ | -------------- |
|       Top-K        |       1        |
|       Top-P        |     0.001      |
|    temperature     |      0.1       |
| repetition_penalty |      1.05      |

#### 单一测试demo执行时，指定max_length=min_length=128，固定输出长度。
|     parameter      |      Value     |
| ------------------ | -------------- |
|     min_length     |       128      |
|     min_length     |       128      |

## 在 NVIDIA A800-SXM4-80GB 上测试的性能如下：

#### 下方表格中所示性能对应的输入输出大小。
|     parameter                   |      Value      |
| ------------------------------- | --------------- |
|  single_image_input_tokens_len  |  1428 tokens    |
|  multi_image_input_tokens_len   |  1304 tokens    |
|  output_tokens_len              |  128 tokens     |

#### 单图测试性能
|             model              | Paddle Inference wint8 | Paddle Inference|    PyTorch     | VLLM          |
| -----------------------------  | ---------------------  | --------------- | -------------- |-------------- |
| deepseek-ai/deepseek-vl2-small |          1.63 s        |     1.78 s      |      7.50 s    | 1.95s         |

#### 多图测试性能
|             model              | Paddle Inference wint8 | Paddle Inference|    PyTorch     | VLLM          |
| -----------------------------  | ---------------------  | --------------- | -------------- |-------------- |
| deepseek-ai/deepseek-vl2-small |          1.67 s        |     1.85 s      |      7.44 s    | 2.05s         |
